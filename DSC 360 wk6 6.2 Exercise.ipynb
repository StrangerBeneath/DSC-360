{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Title: 6.2 Exercise**\n",
    "# **Author: Michael J. Montana**\n",
    "# **Date: 23 April 2023**\n",
    "# **Modified By: N/A**\n",
    "# **Description: Working with Predictive Models**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from myclassesv3 import Normalize_Corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "   rating       date         variation  \\\n0       5  31-Jul-18  Charcoal Fabric    \n1       5  31-Jul-18  Charcoal Fabric    \n2       4  31-Jul-18    Walnut Finish    \n3       5  31-Jul-18  Charcoal Fabric    \n4       5  31-Jul-18  Charcoal Fabric    \n\n                                                                                      verified_reviews  \\\n0                                                                                        Love my Echo!   \n1                                                                                            Loved it!   \n2  Sometimes while playing a game, you can answer a question correctly but Alexa says you got it wr...   \n3  I have had a lot of fun with this thing. My 4 yr old learns about dinosaurs, i control the light...   \n4                                                                                                Music   \n\n   feedback  \n0         1  \n1         1  \n2         1  \n3         1  \n4         1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>date</th>\n      <th>variation</th>\n      <th>verified_reviews</th>\n      <th>feedback</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>31-Jul-18</td>\n      <td>Charcoal Fabric</td>\n      <td>Love my Echo!</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>31-Jul-18</td>\n      <td>Charcoal Fabric</td>\n      <td>Loved it!</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>31-Jul-18</td>\n      <td>Walnut Finish</td>\n      <td>Sometimes while playing a game, you can answer a question correctly but Alexa says you got it wr...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>31-Jul-18</td>\n      <td>Charcoal Fabric</td>\n      <td>I have had a lot of fun with this thing. My 4 yr old learns about dinosaurs, i control the light...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>31-Jul-18</td>\n      <td>Charcoal Fabric</td>\n      <td>Music</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexa=pd.read_csv('data/amazon_alexa.csv')\n",
    "alexa.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=2d5db5>**1. Using the Amazon Alexa reviews dataset, build a logistic regression model to predict positive or negative feedback based on review text. Be sure to run a test with something random you create (out of sample). Remember: 1 is positive, 0 is negative.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stripping HTML...\n",
      "Expanding Contratcions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michaelmontana\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\michaelmontana\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\bs4\\__init__.py:404: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Accent Markings...\n",
      "Removing Special Characters...\n",
      "Removing Stopwords...\n",
      "Removing Numbers...\n",
      "Your Data is Clean\n"
     ]
    }
   ],
   "source": [
    "norm = Normalize_Corpus() #instantiating class\n",
    "cleanalexa = alexa.copy() #creating copy of data\n",
    "#cleaning data\n",
    "cleanalexa['verified_reviews']= norm.normalize(cleanalexa['verified_reviews'],html_stripping=True, contraction_expansion=True,\n",
    "                                             accented_char_removal=True, text_lower_case=False,\n",
    "                                             text_lemmatization=False, special_char_removal=True,\n",
    "                                             stopword_removal=True, digits_removal=True,stopwords=stopword_list) #passing Tweet content to the selected normalizer functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3150 entries, 0 to 3149\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   rating            3150 non-null   int64 \n",
      " 1   date              3150 non-null   object\n",
      " 2   variation         3150 non-null   object\n",
      " 3   verified_reviews  3150 non-null   object\n",
      " 4   feedback          3150 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 123.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#removing empty rows\n",
    "clean_alexa_NA_free=cleanalexa.dropna().reset_index(drop=True)\n",
    "clean_alexa_NA_free.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\tCV Accuracy (5-fold): [0.93127962 0.94549763 0.93364929 0.93838863 0.94075829]\n",
      "\tMean CV Accuracy: 0.937914691943128\n",
      "\tTest Accuracy: 0.9365384615384615 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "clean_df = clean_alexa_NA_free\n",
    "\n",
    "# split to test and train\n",
    "train_corpus, test_corpus, train_label_nums, test_label_nums,train_label_names, test_label_names = train_test_split(np.array(clean_df['verified_reviews']),\n",
    "                                                                                                                    np.array(clean_df['feedback']),\n",
    "                                                                                                                    np.array(clean_df['variation']),\n",
    "                                                                                                                    test_size=0.33, random_state=42)\n",
    "#Building BOW\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0)\n",
    "cv_train_features = cv.fit_transform(train_corpus)\n",
    "# transform test articles into features\n",
    "cv_test_features = cv.transform(test_corpus)\n",
    "# print('Train features shape:', cv_train_features.shape)\n",
    "# print('Test features shape:', cv_test_features.shape, '\\n')\n",
    "\n",
    "# Logistic Regression - page 316\n",
    "print('Logistic Regression:')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=3150, solver='lbfgs',\n",
    "                        C=1, random_state=42, multi_class='auto')\n",
    "lr.fit(cv_train_features, train_label_nums)\n",
    "lr_bow_cv_scores = cross_val_score(lr, cv_train_features, train_label_nums, cv=5)\n",
    "lr_bow_cv_mean_score = np.mean(lr_bow_cv_scores)\n",
    "print('\\tCV Accuracy (5-fold):', lr_bow_cv_scores)\n",
    "print('\\tMean CV Accuracy:', lr_bow_cv_mean_score)\n",
    "lr_bow_test_score = lr.score(cv_test_features, test_label_nums)\n",
    "print('\\tTest Accuracy:', lr_bow_test_score, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "\tCV Accuracy (5-fold): [0.92654028 0.92654028 0.92417062 0.92417062 0.92654028]\n",
      "\thMean CV Accuracy: 0.9255924170616113\n",
      "\tTest Accuracy: 0.9057692307692308 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# build BOW features on train articles\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "\n",
    "# transform test articles into features\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "\n",
    "# Logistic Regression\n",
    "print('Logistic Regression:')\n",
    "# This takes quite a while to run, be patient.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, solver='lbfgs',\n",
    "                        C=1, random_state=42, multi_class='auto')\n",
    "lr.fit(tv_train_features, train_label_nums)\n",
    "lr_tfidf_cv_scores = cross_val_score(lr, tv_train_features, train_label_nums, cv=5)\n",
    "lr_tfidf_cv_mean_score = np.mean(lr_tfidf_cv_scores)\n",
    "print('\\tCV Accuracy (5-fold):', lr_tfidf_cv_scores)\n",
    "print('\\thMean CV Accuracy:', lr_tfidf_cv_mean_score)\n",
    "lr_tfidf_test_score = lr.score(tv_test_features, test_label_nums)\n",
    "print('\\tTest Accuracy:', lr_tfidf_test_score, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=2d5db5>**2. At the end of Chapter 5, the author uses a custom-built class to summarize model performance. This class doesn’t actually exist (from the author) but you can make it a reality. Using the object you have from mnb_predictions, create something similar to the output on page 335. Feel free (but not obligated) to venture further into the label names and numbers (page 336) and confusion matrix (page 337).**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 2); total time=   0.0s\n",
      "{'memory': None, 'steps': [('tfidf', TfidfVectorizer(ngram_range=(1, 2))), ('mnb', MultinomialNB(alpha=0.01))], 'verbose': False, 'tfidf': TfidfVectorizer(ngram_range=(1, 2)), 'mnb': MultinomialNB(alpha=0.01), 'tfidf__analyzer': 'word', 'tfidf__binary': False, 'tfidf__decode_error': 'strict', 'tfidf__dtype': <class 'numpy.float64'>, 'tfidf__encoding': 'utf-8', 'tfidf__input': 'content', 'tfidf__lowercase': True, 'tfidf__max_df': 1.0, 'tfidf__max_features': None, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2), 'tfidf__norm': 'l2', 'tfidf__preprocessor': None, 'tfidf__smooth_idf': True, 'tfidf__stop_words': None, 'tfidf__strip_accents': None, 'tfidf__sublinear_tf': False, 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tfidf__tokenizer': None, 'tfidf__use_idf': True, 'tfidf__vocabulary': None, 'mnb__alpha': 0.01, 'mnb__class_prior': None, 'mnb__fit_prior': True} \n",
      "\n",
      "Modeling tuning results DF:    rank                                                params  \\\n",
      "5     1    {'mnb__alpha': 0.01, 'tfidf__ngram_range': (1, 2)}   \n",
      "4     2    {'mnb__alpha': 0.01, 'tfidf__ngram_range': (1, 1)}   \n",
      "6     3     {'mnb__alpha': 0.1, 'tfidf__ngram_range': (1, 1)}   \n",
      "3     4  {'mnb__alpha': 0.0001, 'tfidf__ngram_range': (1, 2)}   \n",
      "1     5   {'mnb__alpha': 1e-05, 'tfidf__ngram_range': (1, 2)}   \n",
      "0     6   {'mnb__alpha': 1e-05, 'tfidf__ngram_range': (1, 1)}   \n",
      "2     6  {'mnb__alpha': 0.0001, 'tfidf__ngram_range': (1, 1)}   \n",
      "7     8     {'mnb__alpha': 0.1, 'tfidf__ngram_range': (1, 2)}   \n",
      "8     9       {'mnb__alpha': 1, 'tfidf__ngram_range': (1, 1)}   \n",
      "9     9       {'mnb__alpha': 1, 'tfidf__ngram_range': (1, 2)}   \n",
      "\n",
      "   cv score (mean)  cv score (std)  \n",
      "5         0.942180        0.004132  \n",
      "4         0.938389        0.003965  \n",
      "6         0.936967        0.004132  \n",
      "3         0.936493        0.004833  \n",
      "1         0.935071        0.006287  \n",
      "0         0.934597        0.007281  \n",
      "2         0.934597        0.007125  \n",
      "7         0.931280        0.002119  \n",
      "8         0.925118        0.001161  \n",
      "9         0.925118        0.001161   \n",
      "\n",
      "Test Accuracy: 0.9307692307692308 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model tuning for the the multinomial Naive Bayes model\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "mnb_pipeline = Pipeline([('tfidf', TfidfVectorizer()), ('mnb', MultinomialNB())])\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)], 'mnb__alpha': [1e-5, 1e-4, 1e-2, 1e-1, 1]}\n",
    "\n",
    "gs_mnb = GridSearchCV(mnb_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_mnb = gs_mnb.fit(train_corpus, train_label_nums)\n",
    "\n",
    "print(gs_mnb.best_estimator_.get_params(), '\\n')\n",
    "\n",
    "cv_results = gs_mnb.cv_results_\n",
    "results_df = pd.DataFrame({'rank': cv_results['rank_test_score'],\n",
    "                            'params': cv_results['params'],\n",
    "                            'cv score (mean)': cv_results['mean_test_score'],\n",
    "                            'cv score (std)': cv_results['std_test_score']})\n",
    "results_df = results_df.sort_values(by=['rank'], ascending=True)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "print('Modeling tuning results DF:', results_df, '\\n')\n",
    "\n",
    "best_mnb_test_score = gs_mnb.score(test_corpus, test_label_nums)\n",
    "print('Test Accuracy:', best_mnb_test_score, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9308\n",
      "Precision: 0.9279\n",
      "Recall: 0.9308\n",
      "F1 Score: 0.9154\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.31      0.46        99\n",
      "           1       0.93      1.00      0.96       941\n",
      "\n",
      "    accuracy                           0.93      1040\n",
      "   macro avg       0.91      0.65      0.71      1040\n",
      "weighted avg       0.93      0.93      0.92      1040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from myclassesv3 import Model_Evaluation\n",
    "meu=Model_Evaluation() #instantiating class\n",
    "mnb_predictions = gs_mnb.predict(test_corpus) #running model\n",
    "unique_classes = list(set(test_label_nums))\n",
    "meu.get_metrics(true_labels=test_label_nums,\n",
    "                predicted_labels=mnb_predictions)\n",
    "print('')\n",
    "meu.display_classification_report(true_labels=test_label_nums,\n",
    "                                  predicted_labels=mnb_predictions,\n",
    "                                  classes=unique_classes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
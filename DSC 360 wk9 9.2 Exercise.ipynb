{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Title: 9.2 Exercise**\n",
    "# **Author: Michael J. Montana**\n",
    "# **Date: 14 May 2023**\n",
    "# **Modified By: N/A**\n",
    "# **Description: Creating custom Named Entity Recognition (NER) Model from text and comparing the output with spaCy's builin NER model**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import sklearn_crfsuite\n",
    "import nltk\n",
    "from sklearn_crfsuite import metrics as crf_metrics\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from spacy import displacy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=46ab18>**Using the Kaggle NER corpus (ner_database.csv), which you can also find in our GitHub, create a NER tagger using Scikit-learn, which implies creating the NER model.**\n",
    "\n",
    "### I highly encourage you to look at the Author's Notebook for Chapter 8. In the text, this all starts on p. 545 and note the Author's GitHub is a little different than what's in the text. Note that building this model is going to take some time so plan accordingly. For example, the fit() alone was 3 minutes (not too bad, but it could take much longer on your machine).\n",
    "\n",
    "### There's also a package installed by the author in his Notebook (sklearn-crfsuite). He installs it in-line in the Notebook, which may not work with Visual Studio Code. But you can just install it at a terminal."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "#importing data and filling nulls\n",
    "df = pd.read_csv('data/ner_dataset.csv.gz', compression='gzip', encoding='ISO-8859-1')\n",
    "df = df.fillna(method='ffill')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    #current word\n",
    "    word = sent[i][0] #instantiates word\n",
    "    postag = sent[i][1] #instantiates pos\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(), #lowercase\n",
    "        'word[-3:]': word[-3:], #last 3 characters\n",
    "        'word[-2:]': word[-2:], #last 2 characters\n",
    "        'word.isupper()': word.isupper(), #uppercase\n",
    "        'word.istitle()': word.istitle(), #title\n",
    "        'word.isdigit()': word.isdigit(), #digit\n",
    "        'postag': postag, # part of speech tag\n",
    "        'postag[:2]': postag[:2]} #first two characters of POS tag\n",
    "\n",
    "    if i > 0:# previous word\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2]})\n",
    "    else:\n",
    "        features['BOS'] = True #BOS = begining fo sentence\n",
    "\n",
    "    if i < len(sent)-1:#next word\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2]})\n",
    "    else:\n",
    "        features['EOS'] = True #EOS = end of sentence\n",
    "\n",
    "    return features\n",
    "\n",
    "# Generates list of word features for each word in sentence\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "#returns lables\n",
    "def sent2labels(sent):\n",
    "        return [label for token, postag, label in sent]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "#assigns part of speach and entity type to each word\n",
    "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                   s['POS'].values.tolist(),\n",
    "                                                   s['Tag'].values.tolist())]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('Sentence #').apply(agg_func) # grouping by sentence\n",
    "\n",
    "sentences = [s for s in grouped_df] #nesting agg_func output in sentence\n",
    "\n",
    "X = np.array([sent2features(s) for s in sentences], dtype=object)\n",
    "y = np.array([sent2labels(s) for s in sentences], dtype=object)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42) #declaring varibales for training/testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 35969/35969 [00:07<00:00, 4854.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 133629\n",
      "Seconds required: 1.334\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=2.39  loss=1264028.26 active=132637 feature_norm=1.00\n",
      "Iter 2   time=2.41  loss=994059.01 active=131294 feature_norm=4.42\n",
      "Iter 3   time=1.20  loss=776413.87 active=125970 feature_norm=3.87\n",
      "Iter 4   time=5.96  loss=422143.40 active=127018 feature_norm=3.24\n",
      "Iter 5   time=1.20  loss=355775.44 active=129029 feature_norm=4.04\n",
      "Iter 6   time=1.19  loss=264125.22 active=124046 feature_norm=6.10\n",
      "Iter 7   time=1.20  loss=222304.71 active=117183 feature_norm=7.69\n",
      "Iter 8   time=1.20  loss=197827.17 active=110838 feature_norm=8.75\n",
      "Iter 9   time=1.66  loss=176877.92 active=105650 feature_norm=10.41\n",
      "Iter 10  time=1.24  loss=158997.61 active=103459 feature_norm=11.60\n",
      "Iter 11  time=1.21  loss=146328.53 active=100247 feature_norm=13.41\n",
      "Iter 12  time=1.19  loss=137671.14 active=98635 feature_norm=14.69\n",
      "Iter 13  time=1.21  loss=130471.62 active=97462 feature_norm=15.45\n",
      "Iter 14  time=1.21  loss=118841.84 active=94124 feature_norm=17.81\n",
      "Iter 15  time=1.65  loss=112928.42 active=92178 feature_norm=20.21\n",
      "Iter 16  time=1.20  loss=105499.44 active=91978 feature_norm=22.27\n",
      "Iter 17  time=1.21  loss=101994.76 active=91940 feature_norm=23.34\n",
      "Iter 18  time=1.21  loss=96362.28 active=89453 feature_norm=26.63\n",
      "Iter 19  time=1.19  loss=90647.28 active=89021 feature_norm=28.85\n",
      "Iter 20  time=1.20  loss=85521.13 active=87547 feature_norm=32.66\n",
      "Iter 21  time=1.20  loss=81239.75 active=87184 feature_norm=36.05\n",
      "Iter 22  time=1.20  loss=77980.98 active=86649 feature_norm=39.45\n",
      "Iter 23  time=1.66  loss=75036.81 active=86300 feature_norm=41.33\n",
      "Iter 24  time=1.20  loss=70028.55 active=82924 feature_norm=47.18\n",
      "Iter 25  time=3.33  loss=67859.30 active=82277 feature_norm=51.09\n",
      "Iter 26  time=1.49  loss=64640.62 active=81815 feature_norm=54.83\n",
      "Iter 27  time=1.67  loss=61783.61 active=80545 feature_norm=60.05\n",
      "Iter 28  time=1.23  loss=59095.29 active=79506 feature_norm=66.46\n",
      "Iter 29  time=1.67  loss=56799.57 active=79733 feature_norm=70.47\n",
      "Iter 30  time=1.20  loss=54812.68 active=79492 feature_norm=75.32\n",
      "Iter 31  time=1.22  loss=52807.07 active=78965 feature_norm=80.24\n",
      "Iter 32  time=1.22  loss=50790.16 active=78225 feature_norm=88.16\n",
      "Iter 33  time=1.23  loss=49548.49 active=78456 feature_norm=90.54\n",
      "Iter 34  time=1.22  loss=48303.45 active=78007 feature_norm=94.98\n",
      "Iter 35  time=1.22  loss=46171.65 active=76442 feature_norm=106.16\n",
      "Iter 36  time=1.21  loss=45327.99 active=75732 feature_norm=115.55\n",
      "Iter 37  time=1.20  loss=43822.08 active=75408 feature_norm=118.88\n",
      "Iter 38  time=1.22  loss=42688.21 active=74715 feature_norm=125.25\n",
      "Iter 39  time=1.20  loss=41275.71 active=73716 feature_norm=139.21\n",
      "Iter 40  time=1.22  loss=40047.55 active=73576 feature_norm=147.46\n",
      "Iter 41  time=1.21  loss=39265.28 active=73554 feature_norm=151.63\n",
      "Iter 42  time=1.21  loss=38403.33 active=72721 feature_norm=159.70\n",
      "Iter 43  time=1.20  loss=37608.69 active=72627 feature_norm=165.70\n",
      "Iter 44  time=1.21  loss=36823.99 active=71771 feature_norm=172.98\n",
      "Iter 45  time=1.19  loss=36326.35 active=70178 feature_norm=184.40\n",
      "Iter 46  time=1.17  loss=35883.80 active=69283 feature_norm=186.01\n",
      "Iter 47  time=1.18  loss=35560.99 active=68923 feature_norm=190.20\n",
      "Iter 48  time=1.15  loss=35404.76 active=67538 feature_norm=199.98\n",
      "Iter 49  time=1.63  loss=35012.55 active=67985 feature_norm=200.64\n",
      "Iter 50  time=1.21  loss=34929.44 active=68033 feature_norm=200.67\n",
      "Iter 51  time=1.16  loss=34693.21 active=67122 feature_norm=201.84\n",
      "Iter 52  time=2.45  loss=34629.25 active=66830 feature_norm=201.25\n",
      "Iter 53  time=1.20  loss=34459.64 active=66761 feature_norm=202.56\n",
      "Iter 54  time=1.62  loss=34344.14 active=66577 feature_norm=203.72\n",
      "Iter 55  time=1.16  loss=34165.12 active=66051 feature_norm=205.31\n",
      "Iter 56  time=1.16  loss=34162.67 active=64890 feature_norm=206.81\n",
      "Iter 57  time=1.16  loss=33943.85 active=65312 feature_norm=207.03\n",
      "Iter 58  time=1.16  loss=33886.19 active=64897 feature_norm=207.50\n",
      "Iter 59  time=1.20  loss=33780.88 active=64020 feature_norm=208.77\n",
      "Iter 60  time=1.20  loss=33666.08 active=63580 feature_norm=209.40\n",
      "Iter 61  time=1.20  loss=33571.12 active=63159 feature_norm=210.40\n",
      "Iter 62  time=1.17  loss=33488.40 active=63013 feature_norm=210.87\n",
      "Iter 63  time=1.42  loss=33397.52 active=62694 feature_norm=211.68\n",
      "Iter 64  time=1.17  loss=33317.69 active=62488 feature_norm=212.22\n",
      "Iter 65  time=1.19  loss=33247.01 active=62238 feature_norm=212.80\n",
      "Iter 66  time=1.19  loss=33173.26 active=62029 feature_norm=213.27\n",
      "Iter 67  time=1.15  loss=33108.73 active=61781 feature_norm=213.91\n",
      "Iter 68  time=1.17  loss=33052.25 active=61575 feature_norm=214.27\n",
      "Iter 69  time=1.18  loss=32996.19 active=61366 feature_norm=214.76\n",
      "Iter 70  time=1.16  loss=32941.28 active=61153 feature_norm=215.10\n",
      "Iter 71  time=1.18  loss=32894.22 active=60966 feature_norm=215.53\n",
      "Iter 72  time=1.17  loss=32853.09 active=60815 feature_norm=215.78\n",
      "Iter 73  time=1.17  loss=32814.22 active=60658 feature_norm=216.15\n",
      "Iter 74  time=1.21  loss=32778.22 active=60513 feature_norm=216.37\n",
      "Iter 75  time=1.19  loss=32743.64 active=60336 feature_norm=216.67\n",
      "Iter 76  time=1.17  loss=32711.92 active=60185 feature_norm=216.86\n",
      "Iter 77  time=1.17  loss=32682.08 active=60090 feature_norm=217.11\n",
      "Iter 78  time=1.17  loss=32654.10 active=59916 feature_norm=217.27\n",
      "Iter 79  time=1.63  loss=32627.76 active=59768 feature_norm=217.54\n",
      "Iter 80  time=1.57  loss=32603.13 active=59701 feature_norm=217.65\n",
      "Iter 81  time=1.19  loss=32580.63 active=59546 feature_norm=217.85\n",
      "Iter 82  time=1.20  loss=32559.76 active=59413 feature_norm=217.96\n",
      "Iter 83  time=1.64  loss=32538.88 active=59278 feature_norm=218.17\n",
      "Iter 84  time=1.20  loss=32520.71 active=59165 feature_norm=218.27\n",
      "Iter 85  time=1.18  loss=32501.10 active=59088 feature_norm=218.47\n",
      "Iter 86  time=1.18  loss=32484.14 active=58988 feature_norm=218.56\n",
      "Iter 87  time=1.18  loss=32467.58 active=58909 feature_norm=218.71\n",
      "Iter 88  time=1.17  loss=32452.86 active=58808 feature_norm=218.80\n",
      "Iter 89  time=1.18  loss=32437.92 active=58717 feature_norm=218.98\n",
      "Iter 90  time=1.16  loss=32424.99 active=58671 feature_norm=219.06\n",
      "Iter 91  time=1.19  loss=32411.01 active=58618 feature_norm=219.21\n",
      "Iter 92  time=1.24  loss=32399.15 active=58552 feature_norm=219.29\n",
      "Iter 93  time=1.18  loss=32386.63 active=58490 feature_norm=219.40\n",
      "Iter 94  time=1.22  loss=32375.74 active=58448 feature_norm=219.48\n",
      "Iter 95  time=1.18  loss=32364.54 active=58374 feature_norm=219.60\n",
      "Iter 96  time=1.18  loss=32354.96 active=58381 feature_norm=219.68\n",
      "Iter 97  time=1.17  loss=32344.27 active=58343 feature_norm=219.80\n",
      "Iter 98  time=1.32  loss=32335.08 active=58304 feature_norm=219.87\n",
      "Iter 99  time=1.21  loss=32324.92 active=58249 feature_norm=219.98\n",
      "Iter 100 time=1.21  loss=32316.67 active=58226 feature_norm=220.04\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 134.922\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 58226 (133629)\n",
      "Number of active attributes: 29279 (90250)\n",
      "Number of active labels: 17 (17)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', #training algorithm limited memory broyden,fletcher, goldfarb, shanno algorithm -- https://towardsdatascience.com/limited-memory-broyden-fletcher-goldfarb-shanno-algorithm-in-ml-net-118dec066ba\n",
    "                           c1=0.1,\n",
    "                           c2=0.1,\n",
    "                           max_iterations=100,\n",
    "                           all_possible_transitions=True,\n",
    "                           verbose=True)\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError: #ignoring the errors\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=46ab18>**1. Run the following sentence through your tagger: “Fourteen days ago, Emperor Palpatine left San Diego, CA for Tatooine to follow Luke Skywalker.” Report on the tags applied to the sentence.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "text=\"Fourteen days ago, Emperor Palpatine left San Diego, CA for Tatooine to follow Luke Skywalker.\"\n",
    "#building words only DataFrame for #3 comparison\n",
    "text2=\"Fourteen days ago Emperor Palpatine left San Diego CA for Tatooine to follow Luke Skywalker\"\n",
    "words=text2.split()\n",
    "word_df= pd.DataFrame(words,columns=['word'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "         word    NER\n0    Fourteen  B-per\n1        days      O\n2         ago      O\n3           ,      O\n4     Emperor  B-per\n5   Palpatine  I-per\n6        left      O\n7         San  B-geo\n8       Diego  I-geo\n9           ,      O\n10         CA  B-org\n11        for      O\n12   Tatooine  B-org\n13         to      O\n14     follow      O\n15       Luke  B-per\n16  Skywalker  I-per\n17          .      O",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>NER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Fourteen</td>\n      <td>B-per</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>days</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ago</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Emperor</td>\n      <td>B-per</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Palpatine</td>\n      <td>I-per</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>left</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>San</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Diego</td>\n      <td>I-geo</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>CA</td>\n      <td>B-org</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>for</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Tatooine</td>\n      <td>B-org</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>to</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>follow</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Luke</td>\n      <td>B-per</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Skywalker</td>\n      <td>I-per</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieves text POS\n",
    "text_tokens = nltk.word_tokenize(text)\n",
    "text_pos = nltk.pos_tag(text_tokens)\n",
    "\n",
    "# Retrieves features\n",
    "features = [sent2features(text_pos)]\n",
    "\n",
    "# Generates labels\n",
    "labels = crf.predict(features)\n",
    "text_labels = labels[0]\n",
    "\n",
    "# Formats report\n",
    "text_ner_df = pd.DataFrame([[token, tag] for token, tag in zip(text_tokens, text_labels)], columns=['word', 'NER'])\n",
    "text_ner_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "word_ner_merge_df=pd.merge(word_df, text_ner_df, on='word', how='left') #joining dataframes on words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=46ab18>**2.Run the same sentence through spaCy’s NER engine.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Fourteen days ago\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n</mark>\n, Emperor \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Palpatine\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n left \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    San Diego\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n, \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    CA\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n for \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Tatooine\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n to follow \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Luke Skywalker\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n.</div></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm') #loading the english model\n",
    "text_nlp = nlp(text) #creates a doc object with provided text using the english model\n",
    "displacy.render(text_nlp, style='ent', jupyter=True) #rendering the entity visual"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "spacy_ner = pd.DataFrame([(word.text, word.ent_type_,word.ent_iob_) for word in text_nlp], columns=['word', 'spaCy', 'spaCy_iob'])# creating a DataFrame for sapCy NER output\n",
    "comparison_df=pd.merge(word_ner_merge_df, spacy_ner, on='word', how='left')#joining for comparison"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=46ab18>**3.Compare and contrast the results – you can do this in your Jupyter Notebook or as a comment in your .py file.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "         word    NER   spaCy spaCy_iob\n0    Fourteen  B-per    DATE         B\n1        days      O    DATE         I\n2         ago      O    DATE         I\n3     Emperor  B-per                 O\n4   Palpatine  I-per  PERSON         B\n5        left      O                 O\n6         San  B-geo     GPE         B\n7       Diego  I-geo     GPE         I\n8          CA  B-org  PERSON         B\n9         for      O                 O\n10   Tatooine  B-org  PERSON         B\n11         to      O                 O\n12     follow      O                 O\n13       Luke  B-per  PERSON         B\n14  Skywalker  I-per  PERSON         I",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>NER</th>\n      <th>spaCy</th>\n      <th>spaCy_iob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Fourteen</td>\n      <td>B-per</td>\n      <td>DATE</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>days</td>\n      <td>O</td>\n      <td>DATE</td>\n      <td>I</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ago</td>\n      <td>O</td>\n      <td>DATE</td>\n      <td>I</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Emperor</td>\n      <td>B-per</td>\n      <td></td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Palpatine</td>\n      <td>I-per</td>\n      <td>PERSON</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>left</td>\n      <td>O</td>\n      <td></td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>San</td>\n      <td>B-geo</td>\n      <td>GPE</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Diego</td>\n      <td>I-geo</td>\n      <td>GPE</td>\n      <td>I</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>CA</td>\n      <td>B-org</td>\n      <td>PERSON</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>for</td>\n      <td>O</td>\n      <td></td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Tatooine</td>\n      <td>B-org</td>\n      <td>PERSON</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>to</td>\n      <td>O</td>\n      <td></td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>follow</td>\n      <td>O</td>\n      <td></td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Luke</td>\n      <td>B-per</td>\n      <td>PERSON</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Skywalker</td>\n      <td>I-per</td>\n      <td>PERSON</td>\n      <td>I</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I- prefix__ before a tag indicates that the tag is inside a chunk.\n",
    "# B- prefix__ before a tag indicates that the tag is the beginning of a chunk.\n",
    "# O-  tag__ indicates that a token belongs to no chunk (outside).\n",
    "\n",
    "# The tags in this dataset are explained as follows:\n",
    "\n",
    "# geo__ = Geographical Entity\n",
    "# org__ = Organization\n",
    "# per__ = Person\n",
    "# gpe__ = Geopolitical Entity\n",
    "# tim__ = Time indicator\n",
    "# art__ = Artifact\n",
    "# eve__ = Event\n",
    "# nat__ = Natural Phenomenon\n",
    "comparison_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=46ab18>**Fourteen days ago**\n",
    "- Both named entity recongition (NER) models idetified Fourteen as the beginning of a chunk\n",
    "- SpaCy identified \"days\" \"ago\" as entities inside the chunk while the text NER (tNER) did not\n",
    "- SpaCy correctly identified the chunk as a date entity while the tNER incorrectly identified it as a person entity\n",
    "\n",
    "## <font color=46ab18>**Emperor Palpatine**\n",
    "- Both idetified Palpatine correctly\n",
    "- spaCy did not include Emperor as part of the person entity but tNER did\n",
    "\n",
    "## <font color=46ab18>**San Diego, CA**\n",
    "- Both models identified San as the begining of the chunk with Diego inside of it\n",
    "- The tNER correclty identified San Diego as geographical entities while spaCy incorrectly identified them as geopolitical\n",
    "- Both models struggled with CA with tNER identifying it as an organization and spaCy identifying it as a person\n",
    "\n",
    "## <font color=46ab18>**Tatooine**\n",
    "- Both models incorrectly identified the entity for Tatooine with tNER identifying it as an organization and spaCy identifying it as a person\n",
    "\n",
    "## <font color=46ab18>**Luke Skywalker**\n",
    "- Both models aced this one idetifing Luke Skywalker as a person\n",
    "\n",
    "## <font color=46ab18>**Overall**\n",
    "- I think both models performed well.  Given the small dataset, the outcomes were very similar and in my opinion to close to tell which is better.  A larger dataset may have yeilded more conclusive results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}